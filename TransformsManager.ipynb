{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforms Manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the base class for manage and visualize data transforms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export\n",
    "\n",
    "#Internal dependencies\n",
    "from exp.nb_AudioCommon import * \n",
    "from exp.nb_DataAugmentation import * \n",
    "from exp.nb_FastWidgets import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export\n",
    "TfmsGroups = [TfmList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export\n",
    "def flatten(x, flattenStrings=False):\n",
    "    '''Transforms [[x]] in [x]'''\n",
    "    if not flattenStrings:\n",
    "        if isinstance(x,str):\n",
    "            return [x]\n",
    "    if isinstance(x, collections.Iterable):\n",
    "        return [a for i in x for a in flatten(i)]\n",
    "    else:\n",
    "        return [x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "def test_flatten():\n",
    "    A=[[1,2],[3,4,5]]\n",
    "    assert [1,2,3,4,5] == flatten(A)\n",
    "    \n",
    "    B = [A]\n",
    "    assert [1,2,3,4,5] == flatten(B)\n",
    "\n",
    "    C = [[1,2],3,[4,5]]\n",
    "    assert [1,2,3,4,5] == flatten(C)\n",
    "    \n",
    "    print('DONE')\n",
    "\n",
    "test_flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "def test_flatten_with_string():\n",
    "    A='abcd'\n",
    "    assert ['abcd'] == flatten(A)\n",
    "\n",
    "    B=['ab','cd']\n",
    "    assert ['ab','cd'] == flatten(B)\n",
    "\n",
    "    C=[['hello'],' ',['world']]\n",
    "    assert ['hello',' ','world'] == flatten(C)\n",
    "\n",
    "    print('DONE')\n",
    "    \n",
    "test_flatten_with_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Export\n",
    "def getTfmList(g:TfmsGroups, up_to_grpup=None)->TfmList:\n",
    "    '''Returns transformations up to specified group included'''\n",
    "    grps = g if up_to_grpup is None else [x for i,x in enumerate(g) if i<=up_to_grpup] \n",
    "    ret = flatten(grps)\n",
    "    ret = [t for t in ret if []!=t] # filter none\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "def test_getTfmList():\n",
    "    g = [[torchaudio.transforms.Scale, torchaudio.transforms.PadTrim],[torchaudio.transforms.MEL]]\n",
    "    assert 3==len(getTfmList(g))\n",
    "    assert 2==len(getTfmList(g,0))\n",
    "    assert 3==len(getTfmList(g,1))\n",
    "    print('DONE')\n",
    "    \n",
    "test_getTfmList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export\n",
    "def applyTfms(tfms:TfmList, x):\n",
    "    '''Apply a list of transformations'''\n",
    "    ret = x\n",
    "    for tfm in tfms:\n",
    "        ret = tfm(ret)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export\n",
    "def removeFirstTfmsByType(tfmsArr, name:str):\n",
    "    ret = tfmsArr.copy()\n",
    "    for i,t in enumerate(ret):\n",
    "        if t.__name__==name:\n",
    "            del ret[i]\n",
    "            return (ret,t)\n",
    "    return tfmsArr,None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "def test_removeFirstTfmsByType():\n",
    "    tfms = get_transforms()\n",
    "    tfmsArr = tfms[0]\n",
    "    tfmsArrRet, found = removeFirstTfmsByType(tfmsArr,'crop_pad')\n",
    "    assert found is not None\n",
    "    assert len(tfmsArr)==(len(tfmsArrRet)+1)\n",
    "    print('DONE')\n",
    "    \n",
    "test_removeFirstTfmsByType()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export\n",
    "def sortByTfmOrderAttr(arr):\n",
    "    return sorted(arr, key=getTfmOrder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sort\n",
      "99 RandTransform(tfm=TfmCrop (cro...\n",
      "10 RandTransform(tfm=TfmPixel (fl...\n",
      "4 RandTransform(tfm=TfmCoord (sy...\n",
      "5 RandTransform(tfm=TfmAffine (r...\n",
      "5 RandTransform(tfm=TfmAffine (z...\n",
      "8 RandTransform(tfm=TfmLighting ...\n",
      "8 RandTransform(tfm=TfmLighting ...\n",
      "After sort\n",
      "4 RandTransform(tfm=TfmCoord (sy...\n",
      "5 RandTransform(tfm=TfmAffine (r...\n",
      "5 RandTransform(tfm=TfmAffine (z...\n",
      "8 RandTransform(tfm=TfmLighting ...\n",
      "8 RandTransform(tfm=TfmLighting ...\n",
      "10 RandTransform(tfm=TfmPixel (fl...\n",
      "99 RandTransform(tfm=TfmCrop (cro...\n"
     ]
    }
   ],
   "source": [
    "def test_sortByTfmOrderAttr():\n",
    "    tfms = get_transforms()\n",
    "    arr = tfms[0]\n",
    "    srt = sortByTfmOrderAttr(arr)\n",
    "    assert len(srt) == len(arr)\n",
    "    srtIds = [getTfmOrder(t) for t in sorted]\n",
    "    for i in range(len(srtIds)-1):\n",
    "        assert srtIds[i]<=srtIds[i+1]\n",
    "    \n",
    "    print('Before sort')\n",
    "    for t in arr:\n",
    "        print(getTfmOrder(t), str(t)[:30] + '...')\n",
    "        \n",
    "    print('After sort')\n",
    "    for t in srt:\n",
    "        print(getTfmOrder(t), str(t)[:30] + '...')\n",
    "        \n",
    "    \n",
    "test_sortByTfmOrderAttr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations Manager\n",
    "\n",
    "In all the situation where there are complex transformtations (ie: an augmented sound that becomes a spectrogram image), TfmsManager can help you to **group transformations into meaningful groups that can be easily tested separately**.\n",
    "Once you've completed the fine tuning step of each group of transformations, **get_tfms()** consolidate your work and generates the final transform list compatible with fast.ai.\n",
    "\n",
    "For example:\n",
    "* IMAGE: bot for train and valid we have a *POST* \"crop_pad\" transformation (that is not considered Data augmentation).\n",
    "* SOUND: no *PRE* transformation but between the data augmentation and post processing there is a \"SIZE\" transformation that ensure that the spectrogram is computed on the minimal required size, saving precious computing resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export\n",
    "class TfmsManager:\n",
    "    def __init__(self, train_tfms_groups:TfmsGroups, valid_tfms_groups:TfmsGroups):\n",
    "        self.train_tfmsg, self.valid_tfmsg = listify(train_tfms_groups), listify(valid_tfms_groups)\n",
    "    \n",
    "    def get_tfms(self)->[TfmList,TfmList]:\n",
    "        return [self.get_train_tfms(up_to_grpup=None), self.get_valid_tfms(up_to_grpup=None)]\n",
    "\n",
    "#Training set functions\n",
    "    def get_train_tfms(self, up_to_grpup=None)->TfmList:\n",
    "        return getTfmList(self.train_tfmsg,up_to_grpup)    \n",
    "        \n",
    "    def apply_train_tfms(self, x, up_to_grpup=None):\n",
    "        return applyTfms(self.get_train_tfms(up_to_grpup),x)\n",
    "    \n",
    "#Validation set functions \n",
    "    def get_valid_tfms(self, up_to_grpup=None)->TfmList:\n",
    "        return getTfmList(self.valid_tfmsg,up_to_grpup)\n",
    "\n",
    "    def apply_valid_tfms(self, x, up_to_grpup=None):\n",
    "        return applyTfms(self.get_train_tfms(up_to_grpup),x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT**: to use TfmsManager with fast.ai use:\n",
    "\n",
    "```python\n",
    "tm = TfmsManager.create_from_main_groups(...)\n",
    "\n",
    "tfms = tm.get_tfms() # THIS ROW ADAPT THE TRANSFORMATIONS TO fast.ai\n",
    "\n",
    "data = (ImageList.from_folder(path) #Where to find the data? -> in path and its subfolders\n",
    "        .split_by_folder()              #How to split in train/valid? -> use the folders\n",
    "        .label_from_folder()            #How to label? -> depending on the folder of the filenames\n",
    "        .add_test_folder()              #Optionally add a test set (here default name is test)\n",
    "        .transform(tfms, size=64)       #Data augmentation? -> use tfms with a size of 64\n",
    "        .databunch())                   #Finally? -> use the defaults for conversion to ImageDataBunch\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted TransformsManager.ipynb to nb_TransformsManager.py\r\n"
     ]
    }
   ],
   "source": [
    "!python notebook2script.py TransformsManager.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
